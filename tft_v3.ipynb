{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e08cf0fba01429d8b044cc3ea848b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d01e359be6fb40c889d98becaed0ed56",
              "IPY_MODEL_910e79a4caa949da89e1efafaeafb08d",
              "IPY_MODEL_f8a525e9b84f499cabdf07e2270bb421"
            ],
            "layout": "IPY_MODEL_cc1290225b5740d5965ce0fc70969145"
          }
        },
        "d01e359be6fb40c889d98becaed0ed56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a73af7226f2a488f9acd35cd978d4288",
            "placeholder": "​",
            "style": "IPY_MODEL_7e23af2b9c2b4f8a9acecfea74ac3d89",
            "value": "Epoch 0: 100%"
          }
        },
        "910e79a4caa949da89e1efafaeafb08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382986970abe4be5936c6d7046d0fca0",
            "max": 7409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9587d64c4da54693bdd10a41db2d8038",
            "value": 7409
          }
        },
        "f8a525e9b84f499cabdf07e2270bb421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de1f4cfca344d6cbca18f6918a2053e",
            "placeholder": "​",
            "style": "IPY_MODEL_1cb7ef72c32649fdb4636c6f92d8811e",
            "value": " 7409/7409 [26:18&lt;00:00,  4.69it/s, v_num=0]"
          }
        },
        "cc1290225b5740d5965ce0fc70969145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a73af7226f2a488f9acd35cd978d4288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e23af2b9c2b4f8a9acecfea74ac3d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "382986970abe4be5936c6d7046d0fca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9587d64c4da54693bdd10a41db2d8038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1de1f4cfca344d6cbca18f6918a2053e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb7ef72c32649fdb4636c6f92d8811e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ScientistLim/ProjectAW/blob/feature%2Fmodel%2Flstm-transformer/tft_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BFtEqFPemxS",
        "outputId": "6d48cc93-129b-4862-afb7-a89304b005f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-forecasting\n",
        "!pip instsall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWXgUYD5cFHh",
        "outputId": "83e729a5-2a0c-407d-c8c8-47abddf78e44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-forecasting\n",
            "  Downloading pytorch_forecasting-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.26.4)\n",
            "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.4.1+cu121)\n",
            "Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.13.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.5.2)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2024.6.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.1)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (71.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.2.0)\n",
            "Downloading pytorch_forecasting-1.1.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning, pytorch-forecasting\n",
            "Successfully installed lightning-2.4.0 lightning-utilities-0.11.7 pytorch-forecasting-1.1.1 pytorch-lightning-2.4.0 torchmetrics-1.4.3\n",
            "ERROR: unknown command \"instsall\" - maybe you meant \"install\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "gD_kZCPKLQFG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "from pytorch_lightning import Trainer, LightningModule\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# 엑셀 파일 불러오기\n",
        "file_path = '/content/drive/MyDrive/종설프1_5팀/전처리.ipynb/four-cycle-16months-feed-pressure-10min.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 데이터 전처리: 필요한 컬럼 설정 (Time, feed_pressure)\n",
        "df['time'] = pd.to_datetime(df['Time'])\n",
        "df['time_idx'] = ((df['time'] - df['time'].min()).dt.total_seconds() // 600).astype(int)  # 5분 간격의 시간 인덱스 생성\n",
        "df['group'] = \"feed_pressure\"  # 그룹화 컬럼 추가\n",
        "\n",
        "# 데이터 확인\n",
        "print(df.head())\n",
        "\n",
        "# 데이터 길이 확인\n",
        "total_length = len(df)\n",
        "print(f\"Total data length: {total_length} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N3FRguGfmEi",
        "outputId": "525badeb-d2f0-4819-944e-34b14bbd5cf2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Time  feed_pressure                time  time_idx  \\\n",
            "0 2023-07-09 04:17:00       0.000000 2023-07-09 04:17:00         0   \n",
            "1 2023-07-09 04:27:00       0.048376 2023-07-09 04:27:00         1   \n",
            "2 2023-07-09 04:37:00       0.086913 2023-07-09 04:37:00         2   \n",
            "3 2023-07-09 04:47:00       0.110682 2023-07-09 04:47:00         3   \n",
            "4 2023-07-09 04:57:00       0.306872 2023-07-09 04:57:00         4   \n",
            "\n",
            "           group  \n",
            "0  feed_pressure  \n",
            "1  feed_pressure  \n",
            "2  feed_pressure  \n",
            "3  feed_pressure  \n",
            "4  feed_pressure  \n",
            "Total data length: 64775 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 준비 및 설정\n",
        "우선 max_encoder_length와 max_prediction_length를 설정하여 데이터의 인코더 및 예측 길이를 정의합니다."
      ],
      "metadata": {
        "id": "PoFmjhBEh4N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max_encoder_length와 max_prediction_length 설정\n",
        "max_encoder_length = 5000  # 30000 - 약 104일 (10분 간격의 데이터)\n",
        "max_prediction_length = 500  # 3000 - 약 10일 예측\n",
        "\n",
        "print(f\"Max encoder length: {max_encoder_length} entries\")\n",
        "print(f\"Max prediction length: {max_prediction_length} entries\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YQs6UADiCoO",
        "outputId": "6b7426a6-9b83-4af9-faf7-2964ebd0ef88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max encoder length: 5000 entries\n",
            "Max prediction length: 500 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TimeSeriesDataSet 생성\n",
        "TimeSeriesDataSet을 사용해 데이터를 생성합니다. 여기에는 타겟, 그룹화 방식, 그리고 변동하는 시계열 컬럼을 정의합니다.\n"
      ],
      "metadata": {
        "id": "mkCDU7vhiD-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TimeSeriesDataSet 생성\n",
        "training = TimeSeriesDataSet(\n",
        "    df,\n",
        "    time_idx=\"time_idx\",\n",
        "    target=\"feed_pressure\",\n",
        "    group_ids=[\"group\"],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    time_varying_unknown_reals=[\"feed_pressure\"],\n",
        "    time_varying_known_reals=[\"time_idx\"],\n",
        "    target_normalizer=GroupNormalizer(groups=[\"group\"], transformation=\"softplus\"),\n",
        "    allow_missing_timesteps=True\n",
        ")"
      ],
      "metadata": {
        "id": "Yn_pCUPwiNFS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader 생성\n",
        "DataLoader를 생성하여 모델이 데이터를 학습할 수 있도록 준비합니다."
      ],
      "metadata": {
        "id": "eTwKJzZniNw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 생성\n",
        "batch_size = 8\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)"
      ],
      "metadata": {
        "id": "KCaB3cO6iOEu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temporal Fusion Transformer 모델 생성\n",
        "Temporal Fusion Transformer 모델을 생성하여 데이터셋을 학습할 준비를 합니다."
      ],
      "metadata": {
        "id": "V0RI59DsiOSK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E-rXp1Tbisv",
        "outputId": "52b88c39-e9b4-4c96-8024-614d67147598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:143: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
            "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Temporal Fusion Transformer 모델 생성\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training,\n",
        "    learning_rate=0.03,\n",
        "    hidden_size=8,  # 줄여서 사용해 보기\n",
        "    attention_head_size=1,\n",
        "    dropout=0.1,\n",
        "    hidden_continuous_size=8,\n",
        "    loss=RMSE(),\n",
        "    log_interval=10,\n",
        "    reduce_on_plateau_patience=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightningModule 정의 및 Trainer 설정\n",
        "PyTorch Lightning을 이용하여 모델 학습을 보다 쉽게 관리할 수 있도록 합니다.\n"
      ],
      "metadata": {
        "id": "OutkHVMSifBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LightningModule 정의\n",
        "class TFTLightningModule(LightningModule):\n",
        "    def __init__(self, tft_model):\n",
        "        super().__init__()\n",
        "        self.tft_model = tft_model.cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.tft_model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = {key: val.cuda().contiguous() for key, val in x.items()}\n",
        "        y = y[0].cuda().contiguous() if isinstance(y, tuple) else y.cuda().contiguous()\n",
        "        y_hat = self(x)\n",
        "        loss = self.tft_model.loss(y_hat[\"prediction\"], y)\n",
        "        self.log(\"train_loss\", loss, batch_size=len(x['encoder_cont'].squeeze()))\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = {key: val.cuda().contiguous() for key, val in x.items()}\n",
        "        y = y[0].cuda().contiguous() if isinstance(y, tuple) else y.cuda().contiguous()\n",
        "        y_hat = self(x)\n",
        "        loss = self.tft_model.loss(y_hat[\"prediction\"], y)\n",
        "        self.log(\"val_loss\", loss, batch_size=len(x['encoder_cont'].squeeze()))\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(self.tft_model.parameters(), lr=0.03)\n",
        "      scheduler = {\n",
        "        'scheduler': ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6, verbose=True),\n",
        "        'monitor': 'val_loss'\n",
        "        }\n",
        "        return [optimizer], [scheduler]"
      ],
      "metadata": {
        "id": "LhI7kRKO2If3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TFT 모델을 LightningModule로 감싸기\n",
        "tft_module = TFTLightningModule(tft)\n",
        "\n",
        "# 학습을 위한 EarlyStopping 설정\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=10, min_delta=1e-4)\n",
        "\n",
        "# 체크포인트 설정\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=\"checkpoints/\",\n",
        "    filename=\"tft-best-checkpoint\",\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "# Learning Rate 스케줄러 설정\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    verbose=True,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Trainer 설정\n",
        "trainer = Trainer(\n",
        "    max_epochs=50,\n",
        "    accelerator='gpu',\n",
        "    devices=1,\n",
        "    gradient_clip_val=0.1,\n",
        "    callbacks=[early_stop_callback, checkpoint_callback, lr_scheduler],\n",
        "    accumulate_grad_batches=2,  # 배치를 2번 누적\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flA2AA5bifhI",
        "outputId": "85d8b4b0-eebd-448e-cb8d-cdb50dd5f6ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 시각화"
      ],
      "metadata": {
        "id": "MV1F_2OiixYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 모델을 GPU로 이동한 후 요약 정보를 출력합니다.\n",
        "tft_module.cuda()\n",
        "\n",
        "# 샘플 입력 준비\n",
        "sample_input = next(iter(training.to_dataloader(train=False, batch_size=1, num_workers=0)))[0]\n",
        "sample_input = {key: val.cuda() for key, val in sample_input.items()}\n",
        "\n",
        "# 모델 구조를 요약하기 위해 사용자 정의 함수 작성\n",
        "def model_summary(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"\\nModel Summary:\")\n",
        "    print(f\"Total Trainable Parameters: {total_params}\")\n",
        "    print(\"Layers and Parameter Sizes:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"{name}: {list(param.size())}\")\n",
        "\n",
        "# 사용자 정의 요약 함수 호출\n",
        "model_summary(tft_module)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K303n53Liw_R",
        "outputId": "950e7036-1a00-47e3-d283-98652feae1fc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Summary:\n",
            "Total Trainable Parameters: 4831\n",
            "Layers and Parameter Sizes:\n",
            "tft_model.prescalers.time_idx.weight: [8, 1]\n",
            "tft_model.prescalers.time_idx.bias: [8]\n",
            "tft_model.prescalers.feed_pressure.weight: [8, 1]\n",
            "tft_model.prescalers.feed_pressure.bias: [8]\n",
            "tft_model.encoder_variable_selection.flattened_grn.resample_norm.mask: [2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.resample_norm.norm.weight: [2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.resample_norm.norm.bias: [2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.fc1.weight: [2, 16]\n",
            "tft_model.encoder_variable_selection.flattened_grn.fc1.bias: [2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.context.weight: [2, 8]\n",
            "tft_model.encoder_variable_selection.flattened_grn.fc2.weight: [2, 2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.fc2.bias: [2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: [4, 2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: [4]\n",
            "tft_model.encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: [2]\n",
            "tft_model.encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: [2]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.fc1.weight: [8, 8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.fc1.bias: [8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.fc2.weight: [8, 8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.fc2.bias: [8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.fc1.weight: [8, 8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.fc1.bias: [8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.fc2.weight: [8, 8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.fc2.bias: [8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.encoder_variable_selection.single_variable_grns.feed_pressure.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.fc1.weight: [8, 8]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.fc1.bias: [8]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.fc2.weight: [8, 8]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.fc2.bias: [8]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.static_context_variable_selection.fc1.weight: [8, 8]\n",
            "tft_model.static_context_variable_selection.fc1.bias: [8]\n",
            "tft_model.static_context_variable_selection.fc2.weight: [8, 8]\n",
            "tft_model.static_context_variable_selection.fc2.bias: [8]\n",
            "tft_model.static_context_variable_selection.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.static_context_variable_selection.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.static_context_variable_selection.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.static_context_variable_selection.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.static_context_initial_hidden_lstm.fc1.weight: [8, 8]\n",
            "tft_model.static_context_initial_hidden_lstm.fc1.bias: [8]\n",
            "tft_model.static_context_initial_hidden_lstm.fc2.weight: [8, 8]\n",
            "tft_model.static_context_initial_hidden_lstm.fc2.bias: [8]\n",
            "tft_model.static_context_initial_hidden_lstm.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.static_context_initial_hidden_lstm.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.static_context_initial_hidden_lstm.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.static_context_initial_hidden_lstm.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.static_context_initial_cell_lstm.fc1.weight: [8, 8]\n",
            "tft_model.static_context_initial_cell_lstm.fc1.bias: [8]\n",
            "tft_model.static_context_initial_cell_lstm.fc2.weight: [8, 8]\n",
            "tft_model.static_context_initial_cell_lstm.fc2.bias: [8]\n",
            "tft_model.static_context_initial_cell_lstm.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.static_context_initial_cell_lstm.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.static_context_initial_cell_lstm.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.static_context_initial_cell_lstm.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.static_context_enrichment.fc1.weight: [8, 8]\n",
            "tft_model.static_context_enrichment.fc1.bias: [8]\n",
            "tft_model.static_context_enrichment.fc2.weight: [8, 8]\n",
            "tft_model.static_context_enrichment.fc2.bias: [8]\n",
            "tft_model.static_context_enrichment.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.static_context_enrichment.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.static_context_enrichment.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.static_context_enrichment.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.lstm_encoder.weight_ih_l0: [32, 8]\n",
            "tft_model.lstm_encoder.weight_hh_l0: [32, 8]\n",
            "tft_model.lstm_encoder.bias_ih_l0: [32]\n",
            "tft_model.lstm_encoder.bias_hh_l0: [32]\n",
            "tft_model.lstm_decoder.weight_ih_l0: [32, 8]\n",
            "tft_model.lstm_decoder.weight_hh_l0: [32, 8]\n",
            "tft_model.lstm_decoder.bias_ih_l0: [32]\n",
            "tft_model.lstm_decoder.bias_hh_l0: [32]\n",
            "tft_model.post_lstm_gate_encoder.fc.weight: [16, 8]\n",
            "tft_model.post_lstm_gate_encoder.fc.bias: [16]\n",
            "tft_model.post_lstm_add_norm_encoder.norm.weight: [8]\n",
            "tft_model.post_lstm_add_norm_encoder.norm.bias: [8]\n",
            "tft_model.static_enrichment.fc1.weight: [8, 8]\n",
            "tft_model.static_enrichment.fc1.bias: [8]\n",
            "tft_model.static_enrichment.context.weight: [8, 8]\n",
            "tft_model.static_enrichment.fc2.weight: [8, 8]\n",
            "tft_model.static_enrichment.fc2.bias: [8]\n",
            "tft_model.static_enrichment.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.static_enrichment.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.static_enrichment.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.static_enrichment.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.multihead_attn.v_layer.weight: [8, 8]\n",
            "tft_model.multihead_attn.v_layer.bias: [8]\n",
            "tft_model.multihead_attn.q_layers.0.weight: [8, 8]\n",
            "tft_model.multihead_attn.q_layers.0.bias: [8]\n",
            "tft_model.multihead_attn.k_layers.0.weight: [8, 8]\n",
            "tft_model.multihead_attn.k_layers.0.bias: [8]\n",
            "tft_model.multihead_attn.w_h.weight: [8, 8]\n",
            "tft_model.post_attn_gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.post_attn_gate_norm.glu.fc.bias: [16]\n",
            "tft_model.post_attn_gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.post_attn_gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.pos_wise_ff.fc1.weight: [8, 8]\n",
            "tft_model.pos_wise_ff.fc1.bias: [8]\n",
            "tft_model.pos_wise_ff.fc2.weight: [8, 8]\n",
            "tft_model.pos_wise_ff.fc2.bias: [8]\n",
            "tft_model.pos_wise_ff.gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.pos_wise_ff.gate_norm.glu.fc.bias: [16]\n",
            "tft_model.pos_wise_ff.gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.pos_wise_ff.gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.pre_output_gate_norm.glu.fc.weight: [16, 8]\n",
            "tft_model.pre_output_gate_norm.glu.fc.bias: [16]\n",
            "tft_model.pre_output_gate_norm.add_norm.norm.weight: [8]\n",
            "tft_model.pre_output_gate_norm.add_norm.norm.bias: [8]\n",
            "tft_model.output_layer.weight: [1, 8]\n",
            "tft_model.output_layer.bias: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "trainer.fit(tft_module, train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591,
          "referenced_widgets": [
            "2e08cf0fba01429d8b044cc3ea848b82",
            "d01e359be6fb40c889d98becaed0ed56",
            "910e79a4caa949da89e1efafaeafb08d",
            "f8a525e9b84f499cabdf07e2270bb421",
            "cc1290225b5740d5965ce0fc70969145",
            "a73af7226f2a488f9acd35cd978d4288",
            "7e23af2b9c2b4f8a9acecfea74ac3d89",
            "382986970abe4be5936c6d7046d0fca0",
            "9587d64c4da54693bdd10a41db2d8038",
            "1de1f4cfca344d6cbca18f6918a2053e",
            "1cb7ef72c32649fdb4636c6f92d8811e"
          ]
        },
        "id": "roYMfN9xfwVq",
        "outputId": "6afe183e-7253-4024-f5e3-6b7b6600cc6f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type                      | Params | Mode \n",
            "----------------------------------------------------------------\n",
            "0 | tft_model | TemporalFusionTransformer | 4.8 K  | train\n",
            "----------------------------------------------------------------\n",
            "4.8 K     Trainable params\n",
            "0         Non-trainable params\n",
            "4.8 K     Total params\n",
            "0.019     Total estimated model params size (MB)\n",
            "159       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e08cf0fba01429d8b044cc3ea848b82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Early stopping conditioned on metric `val_loss` which is not available. Pass in or modify your `EarlyStopping` callback to use any of the following: `train_loss`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1e7a8792e33e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtft_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         )\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mon_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_train_epoch_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitoring_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_lightning_module_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_train_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_train_epoch_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitoring_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Callback]{callback.state_key}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/early_stopping.py\u001b[0m in \u001b[0;36mon_train_epoch_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_on_train_epoch_end\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_skip_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_early_stopping_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/early_stopping.py\u001b[0m in \u001b[0;36m_run_early_stopping_check\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         if trainer.fast_dev_run or not self._validate_condition_metric(  # disable early_stopping with fast_dev_run\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mlogs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         ):  # short circuit if metric not present\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/early_stopping.py\u001b[0m in \u001b[0;36m_validate_condition_metric\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmonitor_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Early stopping conditioned on metric `val_loss` which is not available. Pass in or modify your `EarlyStopping` callback to use any of the following: `train_loss`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6개월 예측\n",
        "encoder_data = df[df['time_idx'] > df['time_idx'].max() - max_encoder_length]\n",
        "new_prediction_data = pd.DataFrame({\n",
        "    \"Time\": pd.date_range(df[\"Time\"].max() + pd.Timedelta(minutes=10), periods=max_prediction_length, freq=\"10T\"),\n",
        "    \"feed_pressure\": [0] * max_prediction_length,\n",
        "    \"time_idx\": range(df[\"time_idx\"].max() + 1, df[\"time_idx\"].max() + 1 + max_prediction_length),\n",
        "    \"group\": \"feed_pressure\",\n",
        "})\n",
        "\n",
        "new_data = pd.concat([encoder_data, new_prediction_data]).reset_index(drop=True)\n",
        "\n",
        "# 예측 수행\n",
        "new_data_cuda = training.transform(new_data)\n",
        "new_data_cuda = {key: val.cuda() for key, val in new_data_cuda.items()}\n",
        "predictions = tft_module.tft_model.predict(new_data_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "VuGMlohaf-q2",
        "outputId": "40e85ea1-48e6-4446-b8c5-8bca68086dc1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-130e958a5e3e>:4: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  \"Time\": pd.date_range(df[\"Time\"].max() + pd.Timedelta(minutes=10), periods=max_prediction_length, freq=\"10T\"),\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TimeSeriesDataSet' object has no attribute 'transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-130e958a5e3e>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 예측 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnew_data_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mnew_data_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_data_cuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtft_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtft_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TimeSeriesDataSet' object has no attribute 'transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 결과 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Time'], df['feed_pressure'], label='Historical Feed Pressure', color='blue')\n",
        "plt.plot(new_prediction_data['Time'], predictions, label='Predicted Feed Pressure (6 months)', color='red')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Feed Pressure')\n",
        "plt.legend()\n",
        "plt.title('TFT Model Feed Pressure Prediction for Next 6 Months')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VCoOvQNFf9Th"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}